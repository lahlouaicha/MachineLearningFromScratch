# -*- coding: utf-8 -*-
"""Ridge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fiUb0wMkKcnhpIyKXW4ITFt38fusstUL
"""

import numpy as np
import math

class Ridge():    
  """
    This class corresponds to the implementation of the ridge regression model with a mean squared error loss.

    Parameters: 
    - nb_iterations (int): The number of iterations in the gradient descent algorithm.
    - learning_rate (float): The learning rate used to update the parameters during the gradient descent.
    - fit_intercept (boolean): The feature corresponding to adding or not the bias term to the model. 
    - alpha (float): The regularization parameter in Ridge Regression. 
    
    """
  def __init__(self, fit_intercept = True, 
               learning_rate = 0.0001, 
               nb_iterations = 1000,
               alpha = 0.0001):
    """
    Inititialization of attributes of the class.
    """
    self.fit_intercept = fit_intercept
    self.learning_rate = learning_rate
    self.nb_iterations = nb_iterations
    self.alpha = alpha

  def initialize_parameters(self,
                            nb_features):
    """"
    Function that return the an array corresponding to the random initialization of parameters/ weights of the model. 
    """
    w = np.random.uniform(-0.001, 0.001, nb_features)
    return w 
 
  def add_bias(self, X):
    """
    Function that returns the original design matrix with a bias term added to it.  
    """
    X = np.insert(X, 0, 1, axis = 1)
    return X

  def fit(self, X, y):
    """ 
    Method to fit train the model with a Gradient Descent Algotithm. 
    """
    # Adding the bias term if needed 
    if self.fit_intercept == True:
      X = self.add_bias (X)

    # Initialize the parameters 
    nb_features = X.shape[1]
    self.param = self.initialize_parameters(nb_features)

    # Trainning the gradient descent algorithm 

    self.list_loss =  []
    for i in range(self.nb_iterations):
      y_pred = X.dot(self.param)
      loss = np.mean((y - y_pred)**2) + np.linalg.norm(self.param)
      self.list_loss.append(loss)     
      gradient  = -(y - y_pred ).dot(X) + np.sum(self.param)
      self.param -= gradient *self.learning_rate
    
    self.loss = self.list_loss[-1]

  def predict(self, X):
    """
    Function to compute the predictions of the matrix X. 

    X (np.array): Array representing the matrix X of features.
    """
    # Adding the bias term if needed 
    if self.fit_intercept == True:
      X = self.add_bias (X)

    # Compute the predictions
    y_pred = X.dot(self.param)
    return y_pred